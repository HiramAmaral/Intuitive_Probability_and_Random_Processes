{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "- Anywhere this picture occurs indicates a problem I need to check or finish:\n",
    "\n",
    "\n",
    "![finish-me.jpg](https://i.pinimg.com/564x/a4/b6/38/a4b638b7d6926e4f494b1d94459052ff.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Problems\n",
    "\n",
    "### Key:\n",
    "\n",
    "- __(w)__ indicates a __word__ problem\n",
    "- __(f)__ indicates a __formula__ problem\n",
    "- __(c)__ indicates a __computer__ problem\n",
    "- __(t)__ indicates a __theoretical__ problem\n",
    "- ðŸ˜ƒ indicates the answer is available in the back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.1 (w)\n",
    "\n",
    "A fair coin is tossed. If it comes up heads, then $X=1$ and if it comes up tails, then $X=0$. Next, a point is selected at random from the area $A$ if $X=1$ and from area $B$ if $X=0$ as shown in Figure 8.12. Note that the area of the square is $4$ and $A$ and $B$ both have areas of $\\frac{3}{2}$. If the point selected is in an upper quadrant, we set $Y=1$ and if its in a lower quadrant, we set $Y=0$. Find the conditional PMF $p_{Y|X}[j|i]$ for all values of $i$ and $j$. Next, compute $P[Y=0]$.\n",
    "\n",
    "![fig_8_12.PNG](../../figs/fig_8_12.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.2 (w) ðŸ˜ƒ\n",
    "\n",
    "A fair coin is tossed with the outcome mapped into $X=1$ for a head and $X=0$ for a tail. If it comes up heads, then a fair die is tossed. The outcome of the die is denoted $Y$ and is set equal to the number of dots observed. If the coin comes up tails, then we set $Y=0$. Find the conditional PMF $p_{Y|X}[j|i]$ for all values of $i$ and $j$. Next, compute $P[Y=1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.3 (w)\n",
    "\n",
    "A fair coin is tossed 3 times in succession. All the outcomes (i.e., the 3-tuples) are equally likely. The random variables $X$ and $Y$ are defined as:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        X &= \n",
    "            \\begin{cases}\n",
    "                0, &\\text{if outcome of first toss is a tail} \\\\\n",
    "                1, &\\text{if outcome of first toss is a head}\n",
    "            \\end{cases} \\\\\n",
    "           \\\\\n",
    "        Y &= \\text{number of heads observed for the three tosses}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Determine the conditional PMF $p_{Y|X}[j|i]$ for all $i$ and $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.4 (t)\n",
    "\n",
    "Prove that $\\sum_{j=-\\infty}^{\\infty}{ p_{Y|X}[y_j|x_i] }$ for all $x_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.5 (w) ðŸ˜ƒ\n",
    "\n",
    "Are the following functions valid conditional PMFs?\n",
    "\n",
    "- $p_{Y|X}[j|x_i] = (1-x_i)^j x_i$ for $x_i=\\frac{1}{4}, \\frac{2}{4}, \\frac{3}{4}$ and $j=1,2,\\dots$\n",
    "\n",
    "\n",
    "- $p_{Y|X}[j|x_i] = {N\\choose j}x_i^j(1-x_i)^{N-j}$ for $x_i=-\\frac{1}{2}, \\frac{1}{2}$ and $j=0,1,\\dots,N$ \n",
    "\n",
    "\n",
    "- $p_{Y|X}[j|x_i] = cx_i^j$ for $x_i=2$ and $j=2,3,\\dots$ and some constant $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.6 (f) ðŸ˜ƒ\n",
    "\n",
    "If\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    p_{X,Y}[i,j] =\n",
    "        \\begin{cases}\n",
    "            \\frac{1}{6}, &(i,j)=(0,0) \\\\\n",
    "            \\frac{2}{6}, &(i,j)=(0,1) \\\\\n",
    "            \\frac{2}{6}, &(i,j)=(1,0) \\\\\n",
    "            \\frac{1}{6}, &(i,j)=(1,1) \\\\\n",
    "        \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "find $p_{Y|X}$ and $p_{X|Y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.7 (f)\n",
    "\n",
    "Verify the conditional PMF given in (8.10): \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    p_{Y|X}[j|0] =\n",
    "        \\begin{cases}\n",
    "            \\frac{2}{18}, &j=3 \\\\\n",
    "            \\frac{4}{18}, &j=5 \\\\\n",
    "            \\frac{6}{18}, &j=7 \\\\\n",
    "            \\frac{4}{18}, &j=9 \\\\\n",
    "            \\frac{2}{18}, &j=11 \\\\\n",
    "        \\end{cases}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.8 (f) ðŸ˜ƒ\n",
    "\n",
    "For the sample space shown in Figure 8.1 determine $p_{Y|X}$ and $p_{X|Y}$ if all the outcomes are equally likely. Explain your results.\n",
    "\n",
    "![fig_8_1.PNG](../../figs/fig_8_1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.9 (w)\n",
    "\n",
    "Explain the need for the denominator term in (8.11) and (8.12),\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        p_{Y|X}[y_j|x_i] &= \\frac{p_{X,Y}[x_i,y_j]}{ \\sum_j{p_{X,Y}[x_i,y_j]} } \\\\\n",
    "               \\\\\n",
    "        p_{X|Y}[x_i|y_j] &= \\frac{p_{X,Y}[x_i,y_j]}{ \\sum_i{p_{X,Y}[x_i,y_j]} }\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.10 (w)\n",
    "\n",
    "If $p_{Y|X}$ and $p_{Y}$ are known, can you find $p_{X,Y}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.11 (w) ðŸ˜ƒ\n",
    "\n",
    "A box contains three types of replacement bulbs. There is an equal proportion of each type. The types vary in their quality so that the probability that the light bulb *fails* at the $j^{th}$ use is given by:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        p_{Y|X}[j|1] &= 0.01(0.99)^{j-1} \\\\\n",
    "               \\\\\n",
    "        p_{Y|X}[j|2] &= 0.1(0.9)^{j-1} \\\\\n",
    "               \\\\\n",
    "        p_{Y|X}[j|3] &= 0.2(0.8)^{j-1}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "for $j = 1,2,\\dots$. Note that $p_{Y|X}[j|i]$ is the PMF of the bulb failing at the $j^{th}$ use if it is of type $i$. \n",
    "\n",
    "If a bulb is selected at random from the box, what is the probability that it will operate satisfactorily for at least $10$ uses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.12 (f)\n",
    "\n",
    "A joint PMF $p_{X,Y}[i,j]$ has the values shown in Table 8.2. Determine the conditional PMF $P_{Y|X}$. Are the random variables independent?\n",
    "\n",
    "![fig_8_12.PNG](../../figs/table_8_2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.13 (w) ðŸ˜ƒ\n",
    "\n",
    "A random vector $(X,Y)$ has a sample space shown in Figure 8.13 with the sample points depicted as solid circles. The four points are equally probable. Note that the points in Figure 8.13b are the corners of the square shown in Figure 8.13a after rotation by $+45^{\\circ}$. For both cases compute $p_{Y|X}$ and $p_{Y}$ to determine if the random variables are independent.\n",
    "\n",
    "![fig_8_12.PNG](../../figs/fig_8_13.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.14 (t)\n",
    "\n",
    "Use the properties of conditional probability and the definition of the conditional PMF to prove (8.23):\n",
    "\n",
    "$$\n",
    "P[Y\\in A | X=x_i] = \\underset{ \\{j:y_j\\in A\\} }\\sum{ p_{Y|X}[y_j|x_i] }\n",
    "$$\n",
    "\n",
    "Hint: Let $A = \\bigcup_{j}\\{s:Y(s)=y_j \\}$ and note that the sets $\\{s:Y(s)=y_j \\}$ are disjoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.15 (w)\n",
    "\n",
    "If $X$ and $Y$ are independent random variables, find the PMF of $Z=|X-Y|$. Assume that $S_X=\\{0,1,\\dots\\}$ and $S_Y=\\{0,1,\\dots\\}$. *Hint:* The answer is:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        p_{Z}[k] &= \n",
    "            \\begin{cases}\n",
    "                \\sum_{i=0}^{\\infty}{p_{X}[i]p_{Y}[i]}, &k=0 \\\\\n",
    "                \\sum_{i=0}^{\\infty}{ \\big(p_{Y}[i]p_{X}[i+k] + p_{X}[i]p_{Y}[i+k]\\big) }, &k=1,2,\\dots\n",
    "            \\end{cases}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "As an intermediate step show that:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        p_{Z|X}[k|i] &= \n",
    "            \\begin{cases}\n",
    "                p_{Y}[i], &k=0 \\\\\n",
    "                p_{Y}[i+k] + p_{Y}[i-k], &k\\neq 0\n",
    "            \\end{cases}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.16 (w)\n",
    "\n",
    "Two people agree to meet at a specified time. Person A will be late by $i$ minutes with a probability $p_{X}[i] = \\big(\\frac{1}{2} \\big)^{i+1}$ for $i=0,1,\\dots$, while person B will be late by $j$ minutes with a probability $p_{Y}[j] = \\big(\\frac{1}{2} \\big)^{j+1}$ for $j=0,1,\\dots$. The people arrive independently of each other. The first person to arrive will wait a maximum of $2$ minutes for the second person to arrive. If the second person is more than $2$ minutes late, the first person will leave. What is the probability that the two people will meet? *Hint:* use the results from Problem 8.15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.17 (w) ðŸ˜ƒ\n",
    "\n",
    "If $X$ and $Y$ are independent random variables, both of whose PMFs take on values $\\{0,1,2,\\dots\\}$ find the PMF of $Z = \\min(X,Y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.18 (w)\n",
    "\n",
    "If $X$ and $Y$ have the joint PMF:\n",
    "\n",
    "$$\n",
    "p_{X,Y}[i,j] = p_1 p_2 (1-p_1)^{i}(1-p_2)^{j}\n",
    "$$\n",
    "\n",
    "for $i=0,1,\\dots$ and $j=0,1,\\dots$ where $p_1\\in(0,1)$ and $p_2\\in(0,1)$, find $P[Y>X]$ using a conditioning argument. In particular, make use of (8.23):\n",
    "\n",
    "$$\n",
    "P[Y\\in A | X=x_i] = \\sum_{\\{j: y_j\\in A\\}}{ p_{Y|X}[y_j|x_i] }\n",
    "$$\n",
    "\n",
    "and $P[Y>X|X=i] = P[Y>i|X=i]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.19 (f)\n",
    "\n",
    "If $X$ and $Y$ have the joint PMF given in Problem 8.6,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    p_{X,Y}[i,j] =\n",
    "        \\begin{cases}\n",
    "            \\frac{1}{6}, &(i,j)=(0,0) \\\\\n",
    "            \\frac{2}{6}, &(i,j)=(0,1) \\\\\n",
    "            \\frac{2}{6}, &(i,j)=(1,0) \\\\\n",
    "            \\frac{1}{6}, &(i,j)=(1,1) \\\\\n",
    "        \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "find $\\mathbb{E}_{Y|X}[Y|x_i]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.20 (f)\n",
    "\n",
    "If $X$ and $Y$ have the joint PMF:\n",
    "\n",
    "$$\n",
    "p_{X,Y}[i,j] = e^{-\\lambda} \\frac{\\lambda^{j}}{j!} \\bigg( \\frac{1}{2} \\bigg)^{i+1} \n",
    "$$\n",
    "\n",
    "for $i=0,1,\\dots$ and $j=0,1,\\dots$ find $\\mathbb{E}_{Y|X}[Y|i]$ for all $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.21 (f) ðŸ˜ƒ\n",
    " \n",
    "Find the conditional mean of $Y$ given $X$ if the joint PMF is uniformly distributed over the points $S_{X,Y} = \\{(0,0),(1,0),(1,1),(2,0),(2,1),(2,2)\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.22 (f) ðŸ˜ƒ\n",
    "\n",
    "For the joint PMF given in Problem 8.21 determine $var(Y|x_i)$ for all $x_i$. Explain why your results appear to be reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.23 (t)\n",
    "\n",
    "Prove that $var(Y|x_i) = \\mathbb{E}_{Y|X}[Y^2|x_i] - \\mathbb{E}_{Y|X}[Y|x_i]^2$ by using (8.31):\n",
    "\n",
    "$$\n",
    "var(Y|x_i) = \\sum_{j}{ \\big(y_j - \\mathbb{E}_{Y|X}[Y|x_i] \\big)^2 p_{Y|X}[y_j|x_i] }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.24 (f)\n",
    "\n",
    "Find $\\mathbb{E}_{Y}[Y]$ for the joint PMF given in Problem 8.21. Do this by using the definition of the expected value and also by using (8.36):\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{Y}[Y] = \\mathbb{E}_{X}[ \\mathbb{E}_{Y|X}[Y|X] ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.25 (t)\n",
    "\n",
    "Prove the extension of (8.36) which is\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\mathbb{E}_{Y}[g(Y)] = \\mathbb{E}_{X}\\big[\\mathbb{E}_{Y|X}[g(Y)|X]\\big]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $h(X) = \\mathbb{E}_{Y|X}[g(Y)|X]$ is a function of the random variable $X$ which takes on values \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    h(x_i) = \\mathbb{E}_{Y|X}[g(Y)|x_i] = \\sum_{j}{g(y_j)p_{Y|X}[y_j|x_i]}.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "This says that $\\mathbb{E}_{Y}[g(Y)]$ can be computed using the formula\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\mathbb{E}_{Y}[g(Y)] = \\mathbb{E}_{X}\\big[\\mathbb{E}_{Y|X}[g(Y)|X]\\big].\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.26 (t)  \n",
    "\n",
    "In this problem we prove that if $M \\sim Pois(\\lambda)$ and $Y$ conditioned on $M$ is a binomial PMF with parameter $p$, then the unconditional PMF of $Y$ is $Pois(\\lambda p)$. This means that if\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    p_{M}[m] = e^{-\\lambda}\\frac{\\lambda^m}{m!}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "for $m = 0,1,\\dots$ and\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "   p_{Y|M}[j|m] = {m \\choose j} p^{j}(1-p)^{m-j}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "for $j = 0,1,\\dots,m$, then\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    p_{Y}[j] = e^{-\\lambda p}\\frac{(\\lambda p)^J}{j!}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "for $j = 0,1,\\dots$. To prove this you will need to derive the characteristic function of $Y$ and show that it corresponds to a $Pois(\\lambda p)$ random variable. Proceed as follows, making use of the results of Problem 8.25:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\phi_{Y}(\\omega) &= \\mathbb{E}_{Y}[e^{j \\omega Y}] \\\\\n",
    "                         \\\\\n",
    "                         &= \\mathbb{E}_{M}\\big[ \\mathbb{E}_{Y|M}[e^{j \\omega Y} | M] \\big] \\\\\n",
    "                         \\\\\n",
    "                         & \\mathbb{E}_{M}\\bigg[\\big(pe^{j \\omega} + (1-p)\\big)^M \\bigg]\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "and complete the derivation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.27 (t)\n",
    "\n",
    "In Chapter 7 the optimal *linear* predictor of $Y$ based on $X=x_i$ was found. The criterion of optimality was the minimum mean square error (MSE), where the MSE was defined as $\\mathbb{E}_{X,Y}[\\big( Y - (aX+b) \\big)^2]$. In this problem we prove that the best predictor, now allowing for *nonlinear predictors* as well, is given by the conditional mean $\\mathbb{E}_{Y|X}[Y|x_i]$. To prove this we let the predictor be $\\hat Y = g(X)$ and minimize:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\mathbb{E}_{X,Y}[\\big( Y - g(X) \\big)^2] &= \\sum_{i}\\sum_{j}{ \\big(y_j - g(x_i)\\big)^2p_{X,Y}[x_i,y_j] } \\\\\n",
    "                                                 \\\\\n",
    "                                                 &=\\sum_{i} \\bigg[ \\sum_{j} \\big(y_j - g(x_i)\\big)^2 p_{Y|X}[y_j|x_i] \\bigg] p_{X}[x_i] \\\\\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "But since $p_{X}[x_i]$ is nonnegative and we can choose a different value of $g(x_i)$ for each $x_i$, we can equivalently minimize\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "     \\bigg[ \\sum_{j} \\big(y_j - g(x_i)\\big)^2 p_{Y|X}[y_j|x_i] \\bigg]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where we consider $g(x_i)=c$ as a constant. Prove that this is minimized for $g(x_i) = \\mathbb{E}_{Y|X}[Y|x_i]$. Hint: you may wish to review Section 6.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.28 (f) ðŸ˜ƒ\n",
    "\n",
    "For random variables $X$ and $Y$ with the joint PMF \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    p_{X,Y}[i,j] =\n",
    "        \\begin{cases}\n",
    "            \\frac{2}{8}, &(i,j)=(-1,0) \\\\\n",
    "            \\frac{1}{8}, &(i,j)=(0,-1) \\\\\n",
    "            \\frac{3}{8}, &(i,j)=(0,1) \\\\\n",
    "            \\frac{2}{8}, &(i,j)=(1,0) \\\\\n",
    "            0, &\\text{else}\n",
    "        \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "we wish to predict $Y$ based on our knowledge of the outcome of $X$. Find the optimal predictor using the results of Problem 8.27. Also, find the optimal *linear* predictor for this problem (see Section 7.9) and compare your results. Draw a picture of the sample space using solid circles to indicate the sample points in a plane and then plot the prediciton for each outcome of $X=i$ for $i = -1,0,1$. Explain your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up problem here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reults here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.29 (c)\n",
    "\n",
    "Test out the MATLAB program given in Section 8.7 to generate realizations of the vector random variable $(X,Y)$ whose joint PMF is given in Figure 8.8. Do so by estimating the joint PMF or $p_{X,Y}[i,j]$. You may wish to review Section 7.11.\n",
    "\n",
    "![Figure 8.8](../../figs/fig_8_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.30 (w,c) ðŸ˜ƒ\n",
    " \n",
    "For the joint PMF given in Figure 8.8 determine the conditional mean $\\mathbb{E}_{Y|X}[Y|i]$ and then verify your results using a computer simulation. Note that you will have to separate the realizations $(x_m,y_m)$ into two sets, one in which $x_m=0$ and one in which $x_m=1$ and then use the sample average of each set as your estimator.\n",
    "\n",
    "![Figure 8.8](../../figs/fig_8_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.31 (w,c)  \n",
    " \n",
    "For the joint PMF given in Figure 8.8 determine $\\mathbb{E}_{Y}[Y]$. Then verify (8.36), which says that $\\mathbb{E}_{Y}[Y] = \\mathbb{E}_{X}\\big[ \\mathbb{E}_{Y|X}[Y|X] \\big]$, by using your results from Problem 8.30 and computing \n",
    "\n",
    "$$\n",
    "\\widehat{\\mathbb{E}_{Y}[Y]} = \\widehat{\\mathbb{E}_{Y|X}[Y|0]}\\hat p_{X}[0] + \\widehat{\\mathbb{E}_{Y|X}[Y|1]}\\hat p_{X}[1]\n",
    "$$\n",
    "\n",
    "where $\\widehat{\\mathbb{E}_{Y|X}[Y|0]}$ and $\\widehat{\\mathbb{E}_{Y|X}[Y|1]}$ are the values obtained in Problem 8.30. Also, the PMF of $X$, which needs to be estimated, can be done so as described in Section 5.9.\n",
    "\n",
    "![Figure 8.8](../../figs/fig_8_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8.32 (w,c)  \n",
    " \n",
    "For the posterior PMF given by (8.39):\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        p_{Y|X}[y_j|i] &= \\frac{p_{X|Y}[i|y_j] p_{Y}[y_j]}{ \\sum_{j}p_{X|Y}[i|y_j] p_{Y}[y_j] }  \\\\ \n",
    "                       \\\\\n",
    "                       &= \\frac{ y_{j}^{i}(1-y_j)^{N-i} }{ \\sum_{j=0}^{M}{ y_{j}^{i}(1-y_j)^{N-i} } } \n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $y_j = 0, \\frac{1}{M}, \\dots, 1$ and $i = 0, 1, \\dots, N$, plot the PMF for $i=\\frac{N}{2}$, $M=11$, and increasing $N$, say, $N = 10, 30, 50, 70$. What happens as $N$ becomes large? Explain your results. Hint: You will need a computer to evaluate and plot the posterior PMF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "The *posterior* PMF is determined *after* the experiment is performed. It contains all the information about the probability of heads that results from our prior knowledge, summarized by $p_Y$, and our data knowledge, summarized by $p_{X|Y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
